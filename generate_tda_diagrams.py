"""
General script to generate persistence diagrams and barcodes for all datasets and embeddings.
Supports: raw data, VAE embeddings, PCA embeddings, and their UMAP projections.
Uses ModelData generated by generate_model_data.py.
"""
import pickle
import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from ripser import ripser
from persim import plot_diagrams

from generate_model_data import ModelData


def plot_barcodes_unified(dgms, ax=None, max_death=None, colors=None, linewidth=2):
    """
    Unified barcode plot for multiple homology dimensions.
    
    Parameters:
        dgms: list of ndarray diagrams, as returned by ripser()['dgms']
        ax: optional matplotlib axis; if None, creates a new figure
        max_death: optional float to cap infinite intervals
        colors: list of colors per dimension
        linewidth: thickness of bars
    """
    if ax is None:
        fig, ax = plt.subplots(figsize=(10, 4))

    if colors is None:
        colors = ["tab:blue", "tab:orange", "tab:green", "tab:red", "tab:purple"]

    # Determine a maximum value for infinite deaths
    if max_death is None:
        finite_deaths = []
        for dgm in dgms:
            finite = dgm[np.isfinite(dgm[:, 1]), 1]
            if len(finite) > 0:
                finite_deaths.extend(finite)
        max_death = max(finite_deaths) * 1.1 if finite_deaths else 1.0

    y_offset = 0
    for dim, dgm in enumerate(dgms):
        color = colors[dim % len(colors)]
        for birth, death in dgm:
            if not np.isfinite(death):
                death = max_death
            ax.hlines(y_offset, birth, death, colors=color, linewidth=linewidth)
            y_offset += 1

        # Add annotation label for the dimension
        if len(dgm) > 0:
            ax.text(
                max_death * 1.01,
                y_offset - len(dgm) / 2,
                f"H{dim}",
                color=color,
                va="center"
            )

        y_offset += 1  # spacing between dimensions

    ax.set_xlabel("Scale parameter")
    ax.set_ylabel("Feature index")
    ax.invert_yaxis()
    ax.set_ylim(y_offset, -1)


def compute_persistence_diagrams(data, maxdim=2, max_samples=500):
    """
    Compute persistence diagrams from data.
    
    Args:
        data: torch.Tensor or numpy array of shape (n_samples, n_features)
        maxdim: Maximum homology dimension to compute
        max_samples: Maximum number of samples to use (for large datasets)
    
    Returns:
        List of persistence diagrams
    """
    # Convert to numpy if needed
    if isinstance(data, torch.Tensor):
        data_np = data.numpy()
    else:
        data_np = data
    
    # Subsample if too large
    if data_np.shape[0] > max_samples:
        indices = np.random.choice(data_np.shape[0], max_samples, replace=False)
        data_np = data_np[indices]
    
    # Compute persistence diagrams
    result = ripser(data_np, maxdim=maxdim)
    return result['dgms']


def generate_diagrams_for_embedding(
    data, 
    labels, 
    embedding_name, 
    dataset_name, 
    model_name, 
    output_dir='images',
    max_samples=500,
    maxdim=2,
    save_barcodes=True,
    save_diagrams=True
):
    """
    Generate persistence diagrams and barcodes for a single embedding type.
    
    Args:
        data: Embedding data (torch.Tensor or numpy array)
        labels: Labels for coloring (torch.Tensor or numpy array)
        embedding_name: Name of embedding type (e.g., 'raw', 'vae', 'pca', 'umap_raw')
        dataset_name: Name of dataset
        model_name: Name of model
        output_dir: Output directory for images
        max_samples: Maximum samples for persistence computation
        maxdim: Maximum homology dimension
        save_barcodes: Whether to save barcode plots
        save_diagrams: Whether to save persistence diagram plots
    """
    print(f'    Computing persistence diagrams for {embedding_name}...')
    
    # Compute persistence diagrams
    dgms = compute_persistence_diagrams(data, maxdim=maxdim, max_samples=max_samples)
    
    # Create output directories
    barcode_dir = Path(output_dir) / 'barcodes'
    pers_diag_dir = Path(output_dir) / 'pers_diags'
    barcode_dir.mkdir(parents=True, exist_ok=True)
    pers_diag_dir.mkdir(parents=True, exist_ok=True)
    
    # Generate barcode plot
    if save_barcodes:
        fig, ax = plt.subplots(figsize=(12, 5))
        plot_barcodes_unified(dgms, ax=ax)
        ax.set_title(f'Persistence Barcodes - {dataset_name} - {model_name} - {embedding_name}')
        barcode_path = barcode_dir / f'bc_{model_name}_{embedding_name}.png'
        plt.savefig(barcode_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f'      Saved barcode to {barcode_path}')
    
    # Generate persistence diagram plot
    if save_diagrams:
        fig, ax = plt.subplots(figsize=(8, 8))
        plot_diagrams(dgms, show=False, ax=ax)
        ax.set_title(f'Persistence Diagrams - {dataset_name} - {model_name} - {embedding_name}')
        diag_path = pers_diag_dir / f'pd_{model_name}_{embedding_name}.png'
        plt.savefig(diag_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f'      Saved diagram to {diag_path}')


def process_model_data(model_data_path, output_dir='images', max_samples=500, maxdim=2):
    """
    Process a single ModelData file and generate all diagrams.
    
    Args:
        model_data_path: Path to pickled ModelData file
        output_dir: Output directory for images
        max_samples: Maximum samples for persistence computation
        maxdim: Maximum homology dimension
    """
    print(f'\n{"="*60}')
    print(f'Processing: {model_data_path}')
    print(f'{"="*60}')
    
    # Load model data
    with open(model_data_path, 'rb') as f:
        model_data = pickle.load(f)
    
    dataset_name = model_data.dataset_name
    model_name = model_data.model_name
    
    print(f'Dataset: {dataset_name}')
    print(f'Model: {model_name}')
    
    # Define embeddings to process
    embeddings = {
        'raw': model_data.raw_data,
        'vae': model_data.vae_embeddings,
        'pca': model_data.pca_embeddings,
        'umap_raw': model_data.umap_raw,
        'umap_pca': model_data.umap_pca,
        'umap_vae': model_data.umap_vae,
    }
    
    # Process each embedding type
    for emb_name, emb_data in embeddings.items():
        if emb_data is None:
            print(f'    Skipping {emb_name} (not available)')
            continue
        
        try:
            generate_diagrams_for_embedding(
                data=emb_data,
                labels=model_data.labels,
                embedding_name=emb_name,
                dataset_name=dataset_name,
                model_name=model_name,
                output_dir=output_dir,
                max_samples=max_samples,
                maxdim=maxdim
            )
        except Exception as e:
            print(f'    Error processing {emb_name}: {e}')
            import traceback
            traceback.print_exc()
            continue


def process_all_model_data(model_data_dir='model_data', output_dir='images', max_samples=500, maxdim=2):
    """
    Process all ModelData files in a directory.
    
    Args:
        model_data_dir: Directory containing pickled ModelData files
        output_dir: Output directory for images
        max_samples: Maximum samples for persistence computation
        maxdim: Maximum homology dimension
    """
    model_data_path = Path(model_data_dir)
    model_files = list(model_data_path.glob('model_*.pkl'))
    
    print(f'Found {len(model_files)} model data files to process')
    
    for model_file in model_files:
        try:
            process_model_data(
                model_data_path=str(model_file),
                output_dir=output_dir,
                max_samples=max_samples,
                maxdim=maxdim
            )
        except Exception as e:
            print(f'Error processing {model_file}: {e}')
            import traceback
            traceback.print_exc()
            continue


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Generate TDA diagrams and barcodes')
    parser.add_argument('--model_data', type=str, help='Path to pickled ModelData file')
    parser.add_argument('--model_data_dir', type=str, default='model_data', help='Directory containing ModelData files')
    parser.add_argument('--all', action='store_true', help='Process all ModelData files in model_data_dir')
    parser.add_argument('--output_dir', type=str, default='images', help='Output directory for images')
    parser.add_argument('--max_samples', type=int, default=500, help='Maximum samples for persistence computation')
    parser.add_argument('--maxdim', type=int, default=2, help='Maximum homology dimension')
    parser.add_argument('--no_barcodes', action='store_true', help='Skip barcode generation')
    parser.add_argument('--no_diagrams', action='store_true', help='Skip persistence diagram generation')
    
    args = parser.parse_args()
    
    if args.all:
        process_all_model_data(
            model_data_dir=args.model_data_dir,
            output_dir=args.output_dir,
            max_samples=args.max_samples,
            maxdim=args.maxdim
        )
    elif args.model_data:
        process_model_data(
            model_data_path=args.model_data,
            output_dir=args.output_dir,
            max_samples=args.max_samples,
            maxdim=args.maxdim
        )
    else:
        parser.print_help()
        print('\nError: Must specify either --model_data or --all')

