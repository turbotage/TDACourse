"""
General script to generate persistence diagrams and barcodes for all datasets and embeddings.
Supports: raw data, VAE embeddings, PCA embeddings, and their UMAP projections.
Uses ModelData generated by generate_model_data.py.
"""
import pickle
import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from ripser import ripser
from persim import plot_diagrams

from generate_model_data import ModelData


def plot_barcodes_unified(dgms, ax=None, max_death=None, colors=None, linewidth=2):
    """
    Unified barcode plot for multiple homology dimensions.
    
    Parameters:
        dgms: list of ndarray diagrams, as returned by ripser()['dgms']
        ax: optional matplotlib axis; if None, creates a new figure
        max_death: optional float to cap infinite intervals
        colors: list of colors per dimension
        linewidth: thickness of bars
    """
    if ax is None:
        fig, ax = plt.subplots(figsize=(10, 4))

    if colors is None:
        colors = ["tab:blue", "tab:orange", "tab:green", "tab:red", "tab:purple"]

    # Determine a maximum value for infinite deaths
    if max_death is None:
        finite_deaths = []
        for dgm in dgms:
            finite = dgm[np.isfinite(dgm[:, 1]), 1]
            if len(finite) > 0:
                finite_deaths.extend(finite)
        max_death = max(finite_deaths) * 1.1 if finite_deaths else 1.0

    y_offset = 0
    for dim, dgm in enumerate(dgms):
        color = colors[dim % len(colors)]
        for birth, death in dgm:
            if not np.isfinite(death):
                death = max_death
            ax.hlines(y_offset, birth, death, colors=color, linewidth=linewidth)
            y_offset += 1

        # Add annotation label for the dimension
        if len(dgm) > 0:
            ax.text(
                max_death * 1.01,
                y_offset - len(dgm) / 2,
                f"H{dim}",
                color=color,
                va="center"
            )

        y_offset += 1  # spacing between dimensions

    ax.set_xlabel("Scale parameter")
    ax.set_ylabel("Feature index")
    ax.invert_yaxis()
    ax.set_ylim(y_offset, -1)


def compute_persistence_diagrams(data, maxdim=2, max_samples=500):
    """
    Compute persistence diagrams from data.
    
    Args:
        data: torch.Tensor or numpy array of shape (n_samples, n_features)
        maxdim: Maximum homology dimension to compute
        max_samples: Maximum number of samples to use (for large datasets)
    
    Returns:
        List of persistence diagrams
    """
    # Convert to numpy if needed
    if isinstance(data, torch.Tensor):
        data_np = data.numpy()
    else:
        data_np = data
    
    # Subsample if too large
    if data_np.shape[0] > max_samples:
        indices = np.random.choice(data_np.shape[0], max_samples, replace=False)
        data_np = data_np[indices]
    
    # Compute persistence diagrams
    result = ripser(data_np, maxdim=maxdim)
    return result['dgms']


def get_nice_label(embedding_name):
    """
    Convert embedding name to a nicer label for display.
    
    Args:
        embedding_name: Short embedding name (e.g., 'raw', 'vae', 'umap_vae')
    
    Returns:
        Nice label string
    """
    label_map = {
        'raw': 'Raw Data',
        'vae': 'VAE Embeddings',
        'pca': 'PCA Embeddings',
        'umap_raw': 'UMAP (Raw)',
        'umap_pca': 'UMAP (PCA)',
        'umap_vae': 'UMAP (VAE)',
    }
    return label_map.get(embedding_name, embedding_name)


def generate_unified_persistence_diagrams(
    embeddings_dict,
    labels,
    dataset_name,
    model_name,
    output_dir='images',
    max_samples=500,
    maxdim=2,
    exclude_embeddings=None
):
    """
    Generate a single unified figure with all persistence diagrams as subplots.
    
    Args:
        embeddings_dict: Dictionary mapping embedding names to data (e.g., {'raw': data, 'vae': data, ...})
        labels: Labels for coloring (torch.Tensor or numpy array)
        dataset_name: Name of dataset
        model_name: Name of model
        output_dir: Output directory for images
        max_samples: Maximum samples for persistence computation
        maxdim: Maximum homology dimension
        exclude_embeddings: List of embedding names to exclude from the figure (e.g., ['raw', 'pca'])
    
    Returns:
        Path to saved figure
    """
    if exclude_embeddings is None:
        exclude_embeddings = []
    
    # Filter out excluded embeddings and None values
    filtered_embeddings = {
        name: data for name, data in embeddings_dict.items()
        if name not in exclude_embeddings and data is not None
    }
    
    if not filtered_embeddings:
        print('    No embeddings to plot')
        return None
    
    # Compute persistence diagrams for all embeddings
    print(f'    Computing persistence diagrams for {len(filtered_embeddings)} embedding(s)...')
    diagrams_dict = {}
    for emb_name, emb_data in filtered_embeddings.items():
        print(f'      Computing for {emb_name}...')
        try:
            diagrams_dict[emb_name] = compute_persistence_diagrams(
                emb_data, maxdim=maxdim, max_samples=max_samples
            )
        except Exception as e:
            print(f'      Error computing diagrams for {emb_name}: {e}')
            continue
    
    if not diagrams_dict:
        print('    No valid diagrams computed')
        return None
    
    # Create subplots
    n_plots = len(diagrams_dict)
    # Arrange in a grid: 3 columns per row, adjust rows accordingly
    n_cols = min(3, n_plots)
    n_rows = (n_plots + n_cols - 1) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(7 * n_cols, 7 * n_rows), squeeze=False)
    
    # Flatten axes to a list for easier indexing
    axes = axes.flatten().tolist()
    
    # Embedding order for consistent layout
    embedding_order = ['raw', 'vae', 'pca', 'umap_raw', 'umap_pca', 'umap_vae']
    ordered_embeddings = [name for name in embedding_order if name in diagrams_dict]
    # Add any remaining embeddings not in the order list
    for name in diagrams_dict:
        if name not in ordered_embeddings:
            ordered_embeddings.append(name)
    
    # Plot each diagram
    for idx, emb_name in enumerate(ordered_embeddings):
        dgms = diagrams_dict[emb_name]
        ax = axes[idx]
        
        # Plot the persistence diagram
        plot_diagrams(dgms, show=False, ax=ax)
        
        # Set title with nice label and highlighting for vae and umap_vae
        nice_label = get_nice_label(emb_name)
        if emb_name in ['vae', 'umap_vae']:
            # Highlight vae and umap_vae with bold and color
            ax.set_title(nice_label, fontsize=14, fontweight='bold', color='darkblue')
        else:
            ax.set_title(nice_label, fontsize=14, fontweight='normal')
    
    # Hide unused subplots
    for idx in range(len(ordered_embeddings), len(axes)):
        axes[idx].axis('off')
    
    # Add overall title
    fig.suptitle(
        f'Persistence Diagrams - {dataset_name} - {model_name}',
        fontsize=16,
        fontweight='bold',
        y=0.995
    )
    
    # Adjust layout
    plt.tight_layout(rect=[0, 0, 1, 0.98])
    
    # Save figure
    pers_diag_dir = Path(output_dir) / 'pers_diags'
    pers_diag_dir.mkdir(parents=True, exist_ok=True)
    
    # Create filename with excluded embeddings noted if any
    filename_suffix = ''
    if exclude_embeddings:
        filename_suffix = '_excl_' + '_'.join(sorted(exclude_embeddings))
    
    diag_path = pers_diag_dir / f'pd_{model_name}_unified{filename_suffix}.pdf'
    plt.savefig(diag_path, bbox_inches='tight', format='pdf')
    plt.close()
    
    print(f'      Saved unified diagram to {diag_path}')
    return diag_path


def generate_diagrams_for_embedding(
    data, 
    labels, 
    embedding_name, 
    dataset_name, 
    model_name, 
    output_dir='images',
    max_samples=500,
    maxdim=2,
    save_barcodes=True,
    save_diagrams=True
):
    """
    Generate persistence diagrams and barcodes for a single embedding type.
    
    Args:
        data: Embedding data (torch.Tensor or numpy array)
        labels: Labels for coloring (torch.Tensor or numpy array)
        embedding_name: Name of embedding type (e.g., 'raw', 'vae', 'pca', 'umap_raw')
        dataset_name: Name of dataset
        model_name: Name of model
        output_dir: Output directory for images
        max_samples: Maximum samples for persistence computation
        maxdim: Maximum homology dimension
        save_barcodes: Whether to save barcode plots
        save_diagrams: Whether to save persistence diagram plots
    """
    print(f'    Computing persistence diagrams for {embedding_name}...')
    
    # Compute persistence diagrams
    dgms = compute_persistence_diagrams(data, maxdim=maxdim, max_samples=max_samples)
    
    # Create output directories
    barcode_dir = Path(output_dir) / 'barcodes'
    pers_diag_dir = Path(output_dir) / 'pers_diags'
    barcode_dir.mkdir(parents=True, exist_ok=True)
    pers_diag_dir.mkdir(parents=True, exist_ok=True)
    
    # Generate barcode plot
    if save_barcodes:
        fig, ax = plt.subplots(figsize=(12, 5))
        plot_barcodes_unified(dgms, ax=ax)
        ax.set_title(f'Persistence Barcodes - {dataset_name} - {model_name} - {embedding_name}')
        barcode_path = barcode_dir / f'bc_{model_name}_{embedding_name}.png'
        plt.savefig(barcode_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f'      Saved barcode to {barcode_path}')
    
    # Generate persistence diagram plot
    if save_diagrams:
        fig, ax = plt.subplots(figsize=(8, 8))
        plot_diagrams(dgms, show=False, ax=ax)
        ax.set_title(f'Persistence Diagrams - {dataset_name} - {model_name} - {embedding_name}')
        diag_path = pers_diag_dir / f'pd_{model_name}_{embedding_name}.png'
        plt.savefig(diag_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f'      Saved diagram to {diag_path}')


def process_model_data(
    model_data_path,
    output_dir='images',
    max_samples=500,
    maxdim=2,
    exclude_embeddings=None,
    unified_only=True
):
    """
    Process a single ModelData file and generate all diagrams.
    
    Args:
        model_data_path: Path to pickled ModelData file
        output_dir: Output directory for images
        max_samples: Maximum samples for persistence computation
        maxdim: Maximum homology dimension
        exclude_embeddings: List of embedding names to exclude from unified figure (e.g., ['raw', 'pca'])
        unified_only: If True, only generate unified figure; if False, also generate individual plots
    """
    print(f'\n{"="*60}')
    print(f'Processing: {model_data_path}')
    print(f'{"="*60}')
    
    # Load model data
    with open(model_data_path, 'rb') as f:
        model_data = pickle.load(f)
    
    dataset_name = model_data.dataset_name
    model_name = model_data.model_name
    
    print(f'Dataset: {dataset_name}')
    print(f'Model: {model_name}')
    
    # Define embeddings to process
    embeddings = {
        'raw': model_data.raw_data,
        'vae': model_data.vae_embeddings,
        'pca': model_data.pca_embeddings,
        'umap_raw': model_data.umap_raw,
        'umap_pca': model_data.umap_pca,
        'umap_vae': model_data.umap_vae,
    }
    
    # Generate unified figure
    try:
        generate_unified_persistence_diagrams(
            embeddings_dict=embeddings,
            labels=model_data.labels,
            dataset_name=dataset_name,
            model_name=model_name,
            output_dir=output_dir,
            max_samples=max_samples,
            maxdim=maxdim,
            exclude_embeddings=exclude_embeddings
        )
    except Exception as e:
        print(f'    Error generating unified diagram: {e}')
        import traceback
        traceback.print_exc()
    
    # Optionally generate individual plots
    if not unified_only:
        for emb_name, emb_data in embeddings.items():
            if emb_data is None:
                print(f'    Skipping {emb_name} (not available)')
                continue
            
            try:
                generate_diagrams_for_embedding(
                    data=emb_data,
                    labels=model_data.labels,
                    embedding_name=emb_name,
                    dataset_name=dataset_name,
                    model_name=model_name,
                    output_dir=output_dir,
                    max_samples=max_samples,
                    maxdim=maxdim,
                    save_diagrams=True,
                    save_barcodes=True
                )
            except Exception as e:
                print(f'    Error processing {emb_name}: {e}')
                import traceback
                traceback.print_exc()
                continue


def process_all_model_data(
    model_data_dir='model_data',
    output_dir='images',
    max_samples=500,
    maxdim=2,
    exclude_embeddings=None,
    unified_only=True
):
    """
    Process all ModelData files in a directory.
    
    Args:
        model_data_dir: Directory containing pickled ModelData files
        output_dir: Output directory for images
        max_samples: Maximum samples for persistence computation
        maxdim: Maximum homology dimension
        exclude_embeddings: List of embedding names to exclude from unified figure
        unified_only: If True, only generate unified figure; if False, also generate individual plots
    """
    model_data_path = Path(model_data_dir)
    model_files = list(model_data_path.glob('model_*.pkl'))
    
    print(f'Found {len(model_files)} model data files to process')
    
    for model_file in model_files:
        try:
            process_model_data(
                model_data_path=str(model_file),
                output_dir=output_dir,
                max_samples=max_samples,
                maxdim=maxdim,
                exclude_embeddings=exclude_embeddings,
                unified_only=unified_only
            )
        except Exception as e:
            print(f'Error processing {model_file}: {e}')
            import traceback
            traceback.print_exc()
            continue


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Generate TDA diagrams and barcodes')
    parser.add_argument('--model_data', type=str, help='Path to pickled ModelData file')
    parser.add_argument('--model_data_dir', type=str, default='model_data', help='Directory containing ModelData files')
    parser.add_argument('--all', action='store_true', help='Process all ModelData files in model_data_dir')
    parser.add_argument('--output_dir', type=str, default='images', help='Output directory for images')
    parser.add_argument('--max_samples', type=int, default=500, help='Maximum samples for persistence computation')
    parser.add_argument('--maxdim', type=int, default=2, help='Maximum homology dimension')
    parser.add_argument('--no_barcodes', action='store_true', help='Skip barcode generation (for individual plots)')
    parser.add_argument('--no_diagrams', action='store_true', help='Skip persistence diagram generation (for individual plots)')
    parser.add_argument(
        '--exclude',
        type=str,
        nargs='+',
        help='Embedding names to exclude from unified figure (e.g., --exclude raw pca)'
    )
    parser.add_argument(
        '--individual_also',
        action='store_true',
        help='Also generate individual plots in addition to unified figure (default: only unified figure)'
    )
    
    args = parser.parse_args()
    
    # Determine if we should generate individual plots
    unified_only = not args.individual_also
    
    if args.all:
        process_all_model_data(
            model_data_dir=args.model_data_dir,
            output_dir=args.output_dir,
            max_samples=args.max_samples,
            maxdim=args.maxdim,
            exclude_embeddings=args.exclude,
            unified_only=unified_only
        )
    elif args.model_data:
        process_model_data(
            model_data_path=args.model_data,
            output_dir=args.output_dir,
            max_samples=args.max_samples,
            maxdim=args.maxdim,
            exclude_embeddings=args.exclude,
            unified_only=unified_only
        )
    else:
        parser.print_help()
        print('\nError: Must specify either --model_data or --all')

